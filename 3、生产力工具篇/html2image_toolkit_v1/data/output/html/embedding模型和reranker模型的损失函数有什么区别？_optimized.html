<html lang="zh-CN">
<head>
<meta charset="utf-8"/>
<title>
   embedding模型和reranker模型的损失函数有什么区别？
  </title>
<style>
   * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }
        body { 
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "PingFang SC", "Microsoft YaHei", sans-serif; 
            max-width: 1000px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
            background: white;
        }
        
        /* 目录样式 */
        .toc-container {
            background-color: #f8fafc;
            border: 1px solid #e2e8f0;
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0;
            max-width: 800px;
        }
        .toc-title {
            font-size: 1.2em;
            font-weight: bold;
            color: #2d3748;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 2px solid #4299e1;
        }
        .toc ul {
            list-style-type: none;
            padding-left: 0;
        }
        .toc li {
            margin: 8px 0;
            line-height: 1.4;
        }
        .toc a {
            color: #4a5568;
            text-decoration: none;
            transition: color 0.2s;
            display: inline-block;
            padding: 2px 0;
        }
        .toc a:hover {
            color: #4299e1;
            text-decoration: underline;
        }
        .toc ul ul {
            padding-left: 20px;
            margin-top: 5px;
        }
        .toc ul ul li {
            font-size: 0.9em;
        }
        
        h1, h2, h3, h4, h5, h6 { 
            margin: 20px 0 10px 0;
            color: #2d3748;
            line-height: 1.3;
            scroll-margin-top: 20px;
        }
        h1 { font-size: 1.8em; margin-top: 10px; }
        h2 { font-size: 1.5em; }
        h3 { font-size: 1.3em; }
        
        p { 
            margin: 12px 0;
            text-align: justify;
        }
        
        /* 图片样式优化 */
        img { 
            display: block;
            max-width: 100%;
            height: auto;
            margin: 15px auto;
            border-radius: 4px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        
        /* 表格样式优化 */
        table {
            border-collapse: collapse;
            width: 100%;
            margin: 15px auto;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
            font-size: 0.9em;
        }
        th, td { 
            border: 1px solid #e2e8f0; 
            padding: 8px 12px; 
            text-align: left;
        }
        th { 
            background-color: #f8fafc;
            font-weight: 600;
        }
        tr:nth-child(even) {
            background-color: #f8fafc;
        }
        
        /* 代码块样式 */
        code { 
            background-color: #f7fafc; 
            padding: 2px 6px;
            border-radius: 3px; 
            font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
            font-size: 0.9em;
        }
        pre { 
            background-color: #f7fafc; 
            padding: 16px; 
            border-radius: 6px; 
            overflow-x: auto;
            margin: 15px 0;
            border-left: 4px solid #4299e1;
        }
        pre code {
            background: none;
            padding: 0;
        }
        
        /* 列表样式 */
        ul, ol {
            margin: 12px 0;
            padding-left: 24px;
        }
        li {
            margin: 4px 0;
        }
        
        /* 引用样式 */
        blockquote {
            border-left: 4px solid #e2e8f0;
            padding: 12px 20px;
            margin: 15px 0;
            background-color: #f8fafc;
            color: #4a5568;
        }
        
        /* 链接样式 */
        a {
            color: #4299e1;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        
        /* 水平线 */
        hr {
            border: none;
            border-top: 1px solid #e2e8f0;
            margin: 20px 0;
        }
        
        /* 添加一些间距和样式优化 */
        .content-wrapper {
            width: 100%;
        }
  </style>
</head>
<body style="padding: 10px; margin: 0 auto;">
<div class="content-wrapper">
<h1 id="embeddingreranker" style="margin: 15px 0 8px 0;">
    embedding模型和reranker模型的损失函数有什么区别？
   </h1>
<p>
    总结下embedding模型和reranker模型的损失函数
   </p>
<div class="toc-container">
<div class="toc-title">
     目录
    </div>
<div class="toc">
<ul>
<li>
<a href="#embeddingreranker">
        embedding模型和reranker模型的损失函数有什么区别？
       </a>
<ul>
<li>
<a href="#_1">
          引言
         </a>
</li>
<li>
<a href="#embedding">
          一、embedding模型
         </a>
<ul>
<li>
<a href="#11-embedding">
            1.1 embedding模型的目标是什么？
           </a>
</li>
<li>
<a href="#12-embedding">
            1.2 embedding模型常用的损失函数有哪些？
           </a>
<ul>
<li>
<a href="#121-contrastive-loss">
              1.2.1 对比损失（Contrastive Loss）
             </a>
</li>
<li>
<a href="#122-triplet-loss">
              1.2.2 三元组损失（Triplet Loss）
             </a>
</li>
<li>
<a href="#123-infonce-loss-softmax">
              1.2.3 InfoNCE Loss（基于 Softmax 的对比学习损失）
             </a>
</li>
<li>
<a href="#124-multiple-negatives-ranking-loss">
              1.2.4 Multiple Negatives Ranking Loss（多负例排序损失）
             </a>
</li>
</ul>
</li>
<li>
<a href="#13-embedding">
            1.3 embedding模型常用的损失函数如何选型？
           </a>
</li>
</ul>
</li>
<li>
<a href="#rerank">
          二、Rerank模型
         </a>
<ul>
<li>
<a href="#21-rerank">
            2.1 Rerank 模型的目标是什么？
           </a>
</li>
<li>
<a href="#22-rerank">
            2.2 Rerank 模型常用的损失函数有哪些？
           </a>
<ul>
<li>
<a href="#221-cross-entropy-loss">
              2.2.1 Cross-Entropy Loss（交叉熵损失）
             </a>
</li>
<li>
<a href="#222-pairwise-ranking-loss">
              2.2.2 Pairwise Ranking Loss（成对排序损失）
             </a>
</li>
<li>
<a href="#223-listwise-loss-lambdaloss">
              2.2.3 Listwise Loss（列表排序损失，如 LambdaLoss）
             </a>
</li>
</ul>
</li>
<li>
<a href="#23-embedding">
            2.3 embedding模型常用的损失函数如何选型？
           </a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<h2 id="_1" style="margin: 15px 0 8px 0;">
    引言
   </h2>
<p>
    embedding模型和reranker模型是LLM RAG系统中的重要组件，作用类似于推荐、搜索领域的先召回再排序。因为目标不同，两个模型常用的损失函数也不相同，此处做个总结，便于复习。
   </p>
<h2 id="embedding" style="margin: 15px 0 8px 0;">
    一、embedding模型
   </h2>
<h3 id="11-embedding" style="margin: 15px 0 8px 0;">
    1.1 embedding模型的目标是什么？
   </h3>
<p>
<strong>
     embedding模型的目标是将文本映射到低维稠密的向量空间中，使得语义相似的文本在向量空间中的距离更近
    </strong>
    ，所以embedding模型的损失函数需要能表示出“相似的文本emb距离更近”的含义。
   </p>
<h3 id="12-embedding" style="margin: 15px 0 8px 0;">
    1.2 embedding模型常用的损失函数有哪些？
   </h3>
<h4 id="121-contrastive-loss" style="margin: 15px 0 8px 0;">
    1.2.1 对比损失（Contrastive Loss）
   </h4>
<ol>
<li>
     核心思想：让正样本对（相似文本）的向量距离尽可能小，负样本对（不相似文本）的向量距离尽可能大。
    </li>
</ol>
<p>
<img alt="" src="D:\LM-Is-All-You-Need\3、生产力工具篇\html2image_toolkit\data\output\images\dd6aede102a627e57fc14e4991a6fb37.jpg" style="display: block; margin: 15px auto; max-width: 100%; height: auto;"/>
</p>
<p>
    其中，p 是正样本对集合， N 是负样本对集合， a 是 margin（边界值），控制负样本对的分离程度。
   </p>
<h4 id="122-triplet-loss" style="margin: 15px 0 8px 0;">
    1.2.2 三元组损失（Triplet Loss）
   </h4>
<p>
    核心思想：给定一个锚点（anchor）、一个正样本（positive）和一个负样本（negative），使锚点与正样本的距离小于锚点与负样本的距离。
   </p>
<p>
<img alt="" src="D:\LM-Is-All-You-Need\3、生产力工具篇\html2image_toolkit\data\output\images\f66a66f63b4b031b31b746644d3b4729.jpg" style="display: block; margin: 15px auto; max-width: 100%; height: auto;"/>
</p>
<p>
    a 是 margin，确保正负样本之间有足够的区分度。
   </p>
<h4 id="123-infonce-loss-softmax" style="margin: 15px 0 8px 0;">
    1.2.3 InfoNCE Loss（基于 Softmax 的对比学习损失）
   </h4>
<p>
    核心思想：在 batch 内计算相似度，使用交叉熵优化正样本对的概率。
   </p>
<p>
<img alt="" src="D:\LM-Is-All-You-Need\3、生产力工具篇\html2image_toolkit\data\output\images\94c9c3f7003b1fe97b5e5ad8b6750139.jpg" style="display: block; margin: 15px auto; max-width: 100%; height: auto;"/>
</p>
<p>
    s(·) 是相似度函数（如余弦相似度）， r 是温度系数，控制分布的平滑程度，r 越小，正负样本的概率差距越大； r 越大，正负样本的概率差距越小。
   </p>
<h4 id="124-multiple-negatives-ranking-loss" style="margin: 15px 0 8px 0;">
    1.2.4 Multiple Negatives Ranking Loss（多负例排序损失）
   </h4>
<p>
    核心思想：类似于 InfoNCE，但更适用于检索任务，优化正样本对的排名。
   </p>
<p>
<img alt="" src="D:\LM-Is-All-You-Need\3、生产力工具篇\html2image_toolkit\data\output\images\b00e0a963b5b81434efcef5e21f34809.jpg" style="display: block; margin: 15px auto; max-width: 100%; height: auto;"/>
</p>
<p>
    通常用于训练双塔结构的 Embedding 模型。
   </p>
<h3 id="13-embedding" style="margin: 15px 0 8px 0;">
    1.3 embedding模型常用的损失函数如何选型？
   </h3>
<p>
    在实际应用中，Embedding 模型通常采用对比学习损失（如 InfoNCE）。
   </p>
<h2 id="rerank" style="margin: 15px 0 8px 0;">
    二、Rerank模型
   </h2>
<h3 id="21-rerank" style="margin: 15px 0 8px 0;">
    2.1 Rerank 模型的目标是什么？
   </h3>
<p>
    Rerank 模型的目标是
    <strong>
     对初步检索到的候选doc进行重新排序，选择最相关的文档
    </strong>
    。
   </p>
<h3 id="22-rerank" style="margin: 15px 0 8px 0;">
    2.2 Rerank 模型常用的损失函数有哪些？
   </h3>
<h4 id="221-cross-entropy-loss" style="margin: 15px 0 8px 0;">
    2.2.1 Cross-Entropy Loss（交叉熵损失）
   </h4>
<p>
    核心思想：将 rerank 任务视为判断query和检索到的doc相关或不相关的分类任务，计算预测概率与真实label的交叉熵。
   </p>
<p>
<img alt="" src="D:\LM-Is-All-You-Need\3、生产力工具篇\html2image_toolkit\data\output\images\262224e08bdb550b202bd37a6eafbe08.jpg" style="display: block; margin: 15px auto; max-width: 100%; height: auto;"/>
</p>
<p>
    yi 是真实标签（1=相关，0=不相关）， pi 是模型预测为相关（正样本）的概率。
   </p>
<h4 id="222-pairwise-ranking-loss" style="margin: 15px 0 8px 0;">
    2.2.2 Pairwise Ranking Loss（成对排序损失）
   </h4>
<p>
    核心思想：优化doc对的相对顺序，使相关doc的得分高于不相关doc。
   </p>
<p>
<img alt="" src="D:\LM-Is-All-You-Need\3、生产力工具篇\html2image_toolkit\data\output\images\8b026c8a3457ab894e08d4fa0af6848d.jpg" style="display: block; margin: 15px auto; max-width: 100%; height: auto;"/>
</p>
<p>
    s(d)是模型对doc d 的评分， a 是 margin，确保正负样本之间有足够的区分度。
   </p>
<h4 id="223-listwise-loss-lambdaloss" style="margin: 15px 0 8px 0;">
    2.2.3 Listwise Loss（列表排序损失，如 LambdaLoss）
   </h4>
<p>
    核心思想：直接优化整个排序列表的质量，考虑doc之间的相对重要性。
   </p>
<p>
<img alt="" src="D:\LM-Is-All-You-Need\3、生产力工具篇\html2image_toolkit\data\output\images\b5d03bddbf0556395621280c3a8d518f.jpg" style="display: block; margin: 15px auto; max-width: 100%; height: auto;"/>
</p>
<p>
    NDCG@k 是归一化折损累积增益，衡量排序质量。
   </p>
<p>
    该损失适用于LTR（ Learning to Rank）任务。
   </p>
<h3 id="23-embedding" style="margin: 15px 0 8px 0;">
    2.3 embedding模型常用的损失函数如何选型？
   </h3>
<p>
    在实际应用中， Rerank 模型更倾向于使用排序优化损失（如 Pairwise Loss）。
   </p>
</div>
</body>
</html>
